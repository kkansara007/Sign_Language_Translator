<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ASL Live Translator</title>
  <!-- Tailwind CSS -->
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    :root { --card: #0b1020; --ink:#e5e7eb; --ink-dim:#9ca3af; --accent:#8b5cf6; --accent-2:#22d3ee; }
    body { background: radial-gradient(1200px 600px at 10% -10%, rgba(139,92,246,.15), transparent),
             radial-gradient(800px 500px at 110% 10%, rgba(34,211,238,.15), transparent),
             #0a0f1f; color: var(--ink); font-family: 'Inter', sans-serif; }
    .card { background: linear-gradient(180deg, rgba(255,255,255,.04), rgba(255,255,255,.02));
           border: 1px solid rgba(255,255,255,.08); box-shadow: 0 8px 30px rgba(0,0,0,.35);
           backdrop-filter: blur(6px); }
    .neon { text-shadow: 0 0 18px rgba(139,92,246,.6); }
    .tag  { background: rgba(139,92,246,.18); border: 1px solid rgba(139,92,246,.35);
           color:#e9d5ff; }
    .pulse-dot { box-shadow: 0 0 0 rgba(34, 211, 238, 0.8); animation: pulse 2s infinite; }
    @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(34, 211, 238, .7); }
      70% { box-shadow: 0 0 0 20px rgba(34, 211, 238, 0); } 100% { box-shadow: 0 0 0 0 rgba(34, 211, 238, 0); } }
    /* Video mirroring */
    #videoEl { transform: scaleX(-1); }
    #overlay { transform: scaleX(-1); }
    dialog .content { color: var(--ink); }
  </style>
  <!-- MediaPipe Hands & drawing utils -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands@0.4/hands.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.min.js"></script>
  <!-- TensorFlow.js for loading and running the model -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js"></script>
</head>
<body class="min-h-screen">
  <header class="max-w-7xl mx-auto px-4 pt-6">
    <div class="flex items-center justify-between">
      <h1 class="text-3xl md:text-4xl font-extrabold neon">ASL Live Translator</h1>
      <div class="flex items-center gap-2">
        <span id="camStatus" class="inline-flex items-center gap-2 text-sm text-slate-300">
          <span id="camDot" class="w-2.5 h-2.5 rounded-full bg-cyan-400 pulse-dot"></span>
          Camera: <b id="camLabel" class="font-semibold">Idle</b>
        </span>
        <a href="#" id="howToBtn" class="ml-4 text-sm underline decoration-dotted hover:text-cyan-300">How to use</a>
      </div>
    </div>
  </header>

  <main class="max-w-7xl mx-auto px-4 py-6 grid lg:grid-cols-2 gap-6">
    <!-- Left: Live feed card -->
    <section class="card rounded-2xl p-4 md:p-6">
      <div class="flex items-center justify-between mb-4">
        <h2 class="text-xl font-semibold">Live Camera</h2>
        <div class="flex gap-2">
          <button id="startBtn" class="px-4 py-2 rounded-xl bg-violet-600 hover:bg-violet-500 font-semibold">Start</button>
          <button id="stopBtn" class="px-4 py-2 rounded-xl bg-slate-700 hover:bg-slate-600 font-semibold">Stop</button>
          <button id="snapBtn" class="px-3 py-2 rounded-xl bg-slate-700 hover:bg-slate-600" title="Capture frame">üì∏</button>
        </div>
      </div>
      <div class="relative rounded-2xl overflow-hidden border border-white/10">
        <video id="videoEl" class="w-full aspect-video bg-black" playsinline muted></video>
        <canvas id="overlay" class="absolute inset-0 w-full h-full pointer-events-none"></canvas>
        <div id="fpsBadge" class="absolute top-3 right-3 text-xs tag px-2 py-1 rounded-full">FPS: --</div>
      </div>

      <div class="mt-4 grid sm:grid-cols-3 gap-3 text-sm">
        <label class="flex items-center justify-between gap-4 bg-white/5 rounded-xl p-3">
          <span>Confidence threshold</span>
          <input id="confRange" type="range" min="0.3" max="0.95" step="0.05" value="0.6" />
        </label>
        <label class="flex items-center justify-between gap-4 bg-white/5 rounded-xl p-3">
          <span>Font size</span>
          <input id="fontRange" type="range" min="16" max="48" step="2" value="22" />
        </label>
        <label class="flex items-center justify-between gap-4 bg-white/5 rounded-xl p-3">
          <span>High contrast</span>
          <input id="contrastToggle" type="checkbox" />
        </label>
      </div>

      <div class="mt-4 text-sm text-slate-300">
        <strong>Fallback / Test</strong>: If camera permission is denied, you can <button id="uploadBtn" class="underline">upload a video</button> to test detection, or follow the server instructions in the error dialog.
        <input id="fileInput" type="file" accept="video/*" class="hidden" />
      </div>
    </section>

    <!-- Right: Translation card -->
    <section class="card rounded-2xl p-4 md:p-6 flex flex-col">
      <div class="flex items-center justify-between mb-4">
        <h2 class="text-xl font-semibold">Translation</h2>
        <div class="flex gap-2">
          <button id="speakBtn" class="px-3 py-2 rounded-xl bg-slate-700 hover:bg-slate-600" title="Speak text">üîä</button>
          <button id="copyBtn" class="px-3 py-2 rounded-xl bg-slate-700 hover:bg-slate-600" title="Copy text">üìã</button>
          <button id="spaceBtn" class="px-3 py-2 rounded-xl bg-slate-700 hover:bg-slate-600" title="Add space">‚ê£</button>
          <button id="clearBtn" class="px-3 py-2 rounded-xl bg-rose-600 hover:bg-rose-500 font-semibold">Clear</button>
        </div>
      </div>
      <div id="outputBox" class="flex-1 rounded-2xl border border-white/10 bg-white/5 p-4 overflow-auto leading-relaxed" style="min-height:12rem; font-size:22px">
        <span id="ghost" class="opacity-60 text-sm">Make a sign in view of the camera‚Ä¶</span>
      </div>
      <div class="mt-4">
        <h3 class="text-sm uppercase tracking-wide text-slate-300 mb-3">Supported signs</h3>
        
        <!-- The list of supported signs will now be determined by your training data -->
        <div class="mb-3">
          <div id="supportedSigns" class="flex flex-wrap gap-1 text-xs">
            <span class="tag px-2 py-1 rounded-full">LOADING...</span>
          </div>
        </div>
      </div>
    </section>

    <!-- Right: Dataset Collection card -->
    <section class="card rounded-2xl p-4 md:p-6 flex flex-col">
      <div class="flex items-center justify-between mb-4">
        <h2 class="text-xl font-semibold">Dataset Collection</h2>
        <div class="flex gap-2 items-center">
            <input type="text" id="labelInput" placeholder="Label (e.g., A)" class="bg-white/5 rounded-xl px-4 py-2 w-28 text-sm" />
            <button id="startCollectBtn" class="px-4 py-2 rounded-xl bg-violet-600 hover:bg-violet-500 font-semibold">Start</button>
            <button id="stopCollectBtn" class="px-4 py-2 rounded-xl bg-slate-700 hover:bg-slate-600 font-semibold" disabled>Stop</button>
        </div>
      </div>
      <div class="flex-1 rounded-2xl border border-white/10 bg-white/5 p-4 overflow-auto leading-relaxed" style="min-height:12rem;">
        <p class="text-sm text-slate-300">
          Status: <span id="collectionStatus" class="font-semibold">Idle</span><br>
          Total sequences: <span id="sampleCount" class="font-semibold">0</span><br>
          Frames in sequence: <span id="framesInSequence" class="font-semibold">0</span>/20
        </p>
      </div>
      <div class="mt-4 flex gap-2">
        <button id="downloadDataBtn" class="flex-1 px-4 py-2 rounded-xl bg-green-600 hover:bg-green-500 font-semibold" disabled>
          Download Dataset
        </button>
        <button id="clearDataBtn" class="flex-1 px-4 py-2 rounded-xl bg-rose-600 hover:bg-rose-500 font-semibold">
          Clear
        </button>
      </div>
    </section>
    
    <!-- Bottom: Practice/Learning Mode -->
    <section class="lg:col-span-2 card rounded-2xl p-6">
      <div class="flex items-center justify-between">
        <h2 class="text-xl font-semibold">Practice Mode</h2>
        <button id="practiceToggle" class="px-4 py-2 rounded-xl bg-slate-700 hover:bg-slate-600">Show tips</button>
      </div>
      <div id="practicePanel" class="mt-4 hidden grid md:grid-cols-3 gap-4 text-sm">
        <div class="bg-white/5 rounded-xl p-4">
          <h4 class="font-semibold mb-2">Frame your hand</h4>
          <p class="text-slate-300">Keep your hand ~50‚Äì80 cm from the camera. Avoid backlight. Use a plain background.</p>
        </div>
        <div class="bg-white/5 rounded-xl p-4">
          <h4 class="font-semibold mb-2">Hold for a moment</h4>
          <p class="text-slate-300">Hold each sign steady for ~400‚Äì600 ms so the system can lock it in and avoid duplicates.</p>
        </div>
        <div class="bg-white/5 rounded-xl p-4">
          <h4 class="font-semibold mb-2">Expanded recognition</h4>
          <p class="text-slate-300">Now uses a custom-trained model for recognition, which can handle any signs you provided in your training data!</p>
        </div>
      </div>

      <div class="mt-6 bg-white/3 rounded-xl p-4 text-sm text-slate-300">
        <strong>Test cases:</strong>
        <ol class="list-decimal list-inside ml-4 mt-2">
          <li>Grant camera permission and make a supported sign ‚Äî expect token appended after a short hold.</li>
          <li>If permission denied, upload any short video of hands (via the upload button) ‚Äî the app will process uploaded video frames as a test case.</li>
          <li>Use the <code>üì∏</code> snapshot button to save a frame ‚Äî validates canvas drawing and overlay rendering.</li>
        </ol>
      </div>
    </section>
  </main>

  <!-- Error / Permission dialog -->
  <dialog id="errDialog" class="card rounded-2xl p-4 text-slate-100 w-[min(720px,96vw)]">
    <div class="flex items-start justify-between mb-3">
      <div>
        <h3 class="text-lg font-semibold">Camera access problem</h3>
        <p class="text-sm text-slate-300 mt-1">Failed to acquire camera. See details and fixes below.</p>
      </div>
      <button id="errClose" class="px-3 py-1 rounded-lg bg-slate-700 hover:bg-slate-600">‚úï</button>
    </div>
    <div class="content text-sm leading-relaxed">
      <p id="errMsg" class="mb-2"></p>
      <ul class="list-disc list-inside text-slate-300 mb-3">
        <li>Make sure you've allowed camera permission for this page.</li>
        <li>Open the page over <strong>https</strong> or <strong>http://localhost</strong> ‚Äî many browsers block camera on <code>file://</code>.</li>
        <li>Check browser settings (Site settings ‚Üí Camera) and unblock camera access for this site.</li>
        <li>If you still can't open the camera, use the <em>Upload video</em> fallback to test the app.</li>
      </ul>
      <div class="flex gap-2">
        <button id="retryBtn" class="px-4 py-2 rounded-xl bg-violet-600 hover:bg-violet-500">Retry</button>
        <button id="serverHelpBtn" class="px-4 py-2 rounded-xl bg-slate-700 hover:bg-slate-600">Run local server</button>
        <button id="useFileBtn" class="px-4 py-2 rounded-xl bg-slate-700 hover:bg-slate-600">Upload video instead</button>
      </div>
      <div id="serverTips" class="hidden mt-3 text-xs text-slate-400 bg-white/3 p-3 rounded">
        <strong>Quick server tips</strong>
        <pre class="mt-2 text-xs"># Python 3
python -m http.server 8000
# Then open: http://localhost:8000/</pre>
      </div>
    </div>
  </dialog>

  <!-- How to use modal -->
  <dialog id="howTo" class="card rounded-2xl p-0 text-slate-100 w-[min(680px,95vw)]">
    <div class="p-5 border-b border-white/10 flex items-start justify-between">
      <h3 class="text-lg font-semibold">How to use</h3>
      <button onclick="howTo.close()" class="px-3 py-1 rounded-lg bg-slate-700 hover:bg-slate-600">‚úï</button>
    </div>
    <div class="p-5 space-y-3 text-sm">
      <ol class="list-decimal list-inside space-y-2">
        <li>Click <b>Start</b> and allow camera access.</li>
        <li>Place your hand in the frame; a skeleton overlay should appear.</li>
        <li>Make a supported sign and hold briefly. The letter/word will appear on the right.</li>
        <li>Use <b>üîä</b> to speak the text, <b>üìã</b> to copy, <b>‚ê£</b> to insert space, <b>Clear</b> to reset.</li>
        <li>If camera is blocked by the browser, use the <em>Upload video</em> fallback or run the page from <code>http://localhost</code>.</li>
      </ol>
      <p class="text-slate-300">Tip: If FPS is low, reduce other browser tabs or lower your camera resolution by editing the constraints in the code.</p>
    </div>
    <div class="p-5 border-t border-white/10 text-right">
      <button onclick="howTo.close()" class="px-4 py-2 rounded-xl bg-violet-600 hover:bg-violet-500">Got it</button>
    </div>
  </dialog>

  <footer class="max-w-7xl mx-auto px-4 pb-10 text-center text-xs text-slate-400">
    Made to help you guys!
  </footer>

  <script>
    // ====== UI Elements ======
    const videoEl = document.getElementById('videoEl');
    const canvas = document.getElementById('overlay');
    const ctx = canvas.getContext('2d');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const copyBtn = document.getElementById('copyBtn');
    const speakBtn = document.getElementById('speakBtn');
    const spaceBtn = document.getElementById('spaceBtn');
    const clearBtn = document.getElementById('clearBtn');
    const outputBox = document.getElementById('outputBox');
    const ghost = document.getElementById('ghost');
    const confRange = document.getElementById('confRange');
    const fontRange = document.getElementById('fontRange');
    const contrastToggle = document.getElementById('contrastToggle');
    const fpsBadge = document.getElementById('fpsBadge');
    const camLabel = document.getElementById('camLabel');
    const camDot = document.getElementById('camDot');
    const howToBtn = document.getElementById('howToBtn');
    const howTo = document.getElementById('howTo');
    const practiceToggle = document.getElementById('practiceToggle');
    const practicePanel = document.getElementById('practicePanel');
    const snapBtn = document.getElementById('snapBtn');
    const errDialog = document.getElementById('errDialog');
    const errMsg = document.getElementById('errMsg');
    const retryBtn = document.getElementById('retryBtn');
    const serverHelpBtn = document.getElementById('serverHelpBtn');
    const serverTips = document.getElementById('serverTips');
    const useFileBtn = document.getElementById('useFileBtn');
    const errClose = document.getElementById('errClose');
    const uploadBtn = document.getElementById('uploadBtn');
    const fileInput = document.getElementById('fileInput');
    const supportedSignsEl = document.getElementById('supportedSigns');

    howToBtn.addEventListener('click', (e) => { e.preventDefault(); howTo.showModal(); });
    practiceToggle.addEventListener('click', () => practicePanel.classList.toggle('hidden'));
    uploadBtn.addEventListener('click', () => fileInput.click());
    useFileBtn.addEventListener('click', () => { errDialog.close(); fileInput.click(); });
    errClose.addEventListener('click', () => errDialog.close());
    serverHelpBtn.addEventListener('click', () => serverTips.classList.toggle('hidden'));

    // ====== State ======
    let mediaStream = null;
    let running = false;
    let lastFrameTs = performance.now();
    let fps = 0;
    let stableGesture = null; // gesture that passed smoothing
    let holdCounter = 0; // frames of same gesture
    const HOLD_FRAMES = 12; // ~400ms at 30fps
    let cooldown = 0; // frames to wait after appending a token

    // ====== Dataset Collection State ======
    let dataset = [];
    let currentLabel = null;
    let isCollectingData = false;
    const labelInput = document.getElementById('labelInput');
    const startCollectBtn = document.getElementById('startCollectBtn');
    const stopCollectBtn = document.getElementById('stopCollectBtn');
    const downloadDataBtn = document.getElementById('downloadDataBtn');
    const clearDataBtn = document.getElementById('clearDataBtn');
    const collectionStatus = document.getElementById('collectionStatus');
    const sampleCount = document.getElementById('sampleCount');
    const framesInSequenceSpan = document.getElementById('framesInSequence');
    let sequence = [];
    const SEQ_LENGTH = 20; // frames per sequence
    let lastSequenceTime = 0; // Timestamp of the last captured sequence
    const DELAY_MS = 4000; // 4 second delay
    
    // Buffer for LSTM model
    let frameBuffer = [];
    const LSTM_SEQ_LEN = 20;

    function setFont(px){ outputBox.style.fontSize = px+'px'; }
    fontRange.addEventListener('input', e => setFont(e.target.value)); setFont(fontRange.value);
    contrastToggle.addEventListener('change', e => {
      document.body.style.background = e.target.checked
        ? '#000'
        : 'radial-gradient(1200px 600px at 10% -10%, rgba(139,92,246,.15), transparent),\nradial-gradient(800px 500px at 110% 10%, rgba(34,211,238,.15), transparent),\n#0a0f1f';
    });

    function appendText(t){
      if(ghost) ghost.remove();
      outputBox.append(document.createTextNode(t));
      outputBox.scrollTop = outputBox.scrollHeight;
    }

    copyBtn.addEventListener('click', async() => {
      try{ await navigator.clipboard.writeText(outputBox.innerText); copyBtn.textContent='‚úî'; setTimeout(()=>copyBtn.textContent='üìã',800); }
      catch(e){ showError(e); }
    });
    spaceBtn.addEventListener('click', ()=> appendText(' '));
    clearBtn.addEventListener('click', ()=> outputBox.textContent='');
    speakBtn.addEventListener('click', ()=> {
      const utter = new SpeechSynthesisUtterance(outputBox.innerText.trim());
      utter.lang = 'en-US'; utter.rate = 1; speechSynthesis.speak(utter);
    });

    // ====== Model Prediction ======
    let gestureModel = null;
    let LABELS = []; 

    async function loadModel() {
      try {
        camLabel.textContent = 'Loading model...';

        // Load the trained model (relative path)
        gestureModel = await tf.loadLayersModel('./model_tfjs/model.json');

        // Quick validation: ensure model has an input shape
        if (!gestureModel.inputs || gestureModel.inputs.length === 0) {
          throw new Error("Loaded model has no inputs. Make sure model.json has an InputLayer with batch_input_shape or input_shape.");
        }

        // Print model summary to console (helps debug shapes)
        try { gestureModel.summary(); } catch (err) { console.log("Model summary unavailable:", err); }

        // Load labels file
        const response = await fetch("./model_labels.json");
        if (!response.ok) throw new Error("Could not load model_labels.json");
        LABELS = await response.json();

        // Populate supported signs UI
        supportedSignsEl.innerHTML = '';
        LABELS.forEach(label => {
          const span = document.createElement('span');
          span.className = 'tag px-2 py-1 rounded-full';
          span.textContent = label;
          supportedSignsEl.appendChild(span);
        });

        camLabel.textContent = 'Ready';
        console.log('Model and labels loaded successfully.');
        console.log('Model input shape(s):', gestureModel.inputs.map(i => i.shape));
      } catch (e) {
        camLabel.textContent = 'Model not found!';
        console.error('Failed to load model:', e);
        showError('Failed to load model or labels. Check model_json presence and input shape (see console).');
      }
    }
    
    // ====== MediaPipe hands setup ======
    const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
    hands.setOptions({
      selfieMode: true,
      maxNumHands: 1,
      modelComplexity: 1,
      minDetectionConfidence: 0.55,
      minTrackingConfidence: 0.5
    });
    hands.onResults(onResults);

    // onResults processes outputs from MediaPipe
    function onResults(results){
      try {
       if (canvas.width !== videoEl.videoWidth) canvas.width = videoEl.videoWidth || canvas.width;
if (canvas.height !== videoEl.videoHeight) canvas.height = videoEl.videoHeight || canvas.height;

ctx.clearRect(0, 0, canvas.width, canvas.height);

// Draw hand landmarks
if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
  for (const landmarks of results.multiHandLandmarks) {
    drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {color: '#8b5cf6', lineWidth: 3});
    drawLandmarks(ctx, landmarks, {color: '#22d3ee', lineWidth: 2});
  }

  // Flatten landmarks into one array for the model
  const landmarks = results.multiHandLandmarks[0].flatMap(p => [p.x, p.y, p.z]);
  frameBuffer.push(landmarks);
  if (frameBuffer.length > LSTM_SEQ_LEN) frameBuffer.shift();

  // Run prediction only when we have enough frames
  if (gestureModel && frameBuffer.length === LSTM_SEQ_LEN) {
    const input = tf.tensor([frameBuffer]);
    const prediction = gestureModel.predict(input);
    const probs = prediction.dataSync();
    const maxIndex = probs.indexOf(Math.max(...probs));
    const confidence = probs[maxIndex];
    input.dispose();
    prediction.dispose();

    fpsBadge.textContent = `FPS: ${fps.toFixed(1)}`;

    if (confidence > parseFloat(confRange.value)) {
      const gesture = LABELS[maxIndex];
      if (gesture === stableGesture) {
        holdCounter++;
        if (holdCounter > HOLD_FRAMES && cooldown === 0) {
          appendText(gesture + ' ');
          cooldown = 10;
        }
      } else {
        stableGesture = gesture;
        holdCounter = 0;
      }
    }

    if (cooldown > 0) cooldown--;
  }
}
}

async function startCamera() {
  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({ video: true });
    videoEl.srcObject = mediaStream;
    await videoEl.play();
    camLabel.textContent = 'Running';
    running = true;
    requestAnimationFrame(processFrame);
  } catch (e) {
    showError(e);
  }
}

function stopCamera() {
  if (mediaStream) {
    mediaStream.getTracks().forEach(t => t.stop());
    running = false;
    camLabel.textContent = 'Stopped';
  }
}

async function processFrame() {
  if (!running) return;
  await hands.send({ image: videoEl });
  const now = performance.now();
  fps = 1000 / (now - lastFrameTs);
  lastFrameTs = now;
  requestAnimationFrame(processFrame);
}

startBtn.addEventListener('click', () => startCamera());
stopBtn.addEventListener('click', () => stopCamera());
loadModel(); // Load model on page load

</body>
</html>
